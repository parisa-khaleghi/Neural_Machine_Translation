{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-31T20:13:54.620262Z","iopub.status.busy":"2023-12-31T20:13:54.619877Z","iopub.status.idle":"2023-12-31T20:13:54.947424Z","shell.execute_reply":"2023-12-31T20:13:54.946047Z","shell.execute_reply.started":"2023-12-31T20:13:54.620232Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/multi30k-de-en/validation/val.en\n","/kaggle/input/multi30k-de-en/validation/val.de\n","/kaggle/input/multi30k-de-en/training/train.de\n","/kaggle/input/multi30k-de-en/training/train.en\n","/kaggle/input/multi30k-de-en/mmt16_task1_test/test.fr\n","/kaggle/input/multi30k-de-en/mmt16_task1_test/._test.fr\n","/kaggle/input/multi30k-de-en/mmt16_task1_test/test.de\n","/kaggle/input/multi30k-de-en/mmt16_task1_test/test.en\n","/kaggle/input/multi30k-de-en/mmt16_task1_test/._test.en\n","/kaggle/input/multi30k-de-en/mmt16_task1_test/._test.de\n","/kaggle/input/french-english/val.txt\n","/kaggle/input/french-english/test.txt\n","/kaggle/input/french-english/train.txt\n","/kaggle/input/french/train.fr\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# Neural Machine Translation by Jointly Learning to Align and Translate\n","\n","## (fr_en dataset in srticle)\n","\n","This notebook to implement the paper titled by [Neural Machine Translation by Jointly Learning to Align and Translate](https://paperswithcode.com/paper/neural-machine-translation-by-jointly). This model achives a very good perplexity, better than the basic encoder-decoder model.\n","\n","## Overview\n","\n","As a reminder, here is a graphical illustration of the general encoder-decoder model:\n","\n","![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/063e9c0127d9e8608b30ef27a0fd99f15f547c40/img/seq2seq1.png)\n","\n","In the previous model, the encoder encodes the whole input sentence into a single-length vector, which would lead to information loss.\n","\n","The following figure illustrates the general idea of the proposed RNNsearch model in this paper:\n","\n","![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/063e9c0127d9e8608b30ef27a0fd99f15f547c40/img/seq2seq7.png)\n","\n","This model handles the bottleneck in the basic model by using attention, i.e, at each time the decoder produces a new target word, it looks to source positions and know the important parts for the translation and this is done by the proposed alignment model.\n","\n","$$w = \\sum_{i}a_ih_i$$\n","\n","a is the attention vector, and H is the source sentence hidden states (annotations).\n","\n","We calculate a new weighted source vector every time-step when decoding, using it as input to our decoder RNN as well as the linear layer to make a prediction."]},{"cell_type":"markdown","metadata":{},"source":["## Preparing Data\n","\n","using torchtext, and using spaCy to assist in the tokenization of the data."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:13:54.950424Z","iopub.status.busy":"2023-12-31T20:13:54.949996Z","iopub.status.idle":"2023-12-31T20:13:57.748007Z","shell.execute_reply":"2023-12-31T20:13:57.746961Z","shell.execute_reply.started":"2023-12-31T20:13:54.950397Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import torchtext\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import Multi30k\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","\n","import spacy\n","import numpy as np\n","import random\n","import math\n","import time\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:13:57.750472Z","iopub.status.busy":"2023-12-31T20:13:57.749253Z","iopub.status.idle":"2023-12-31T20:13:57.757007Z","shell.execute_reply":"2023-12-31T20:13:57.755682Z","shell.execute_reply.started":"2023-12-31T20:13:57.750445Z"},"trusted":true},"outputs":[],"source":["# Seed for reproducibility\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:13:57.761745Z","iopub.status.busy":"2023-12-31T20:13:57.760052Z","iopub.status.idle":"2023-12-31T20:14:11.100458Z","shell.execute_reply":"2023-12-31T20:14:11.099201Z","shell.execute_reply.started":"2023-12-31T20:13:57.761686Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fr-core-news-sm==3.7.0\n","  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n","Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from fr-core-news-sm==3.7.0) (3.7.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.1)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.10.12)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (68.1.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (21.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.24.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_sm')\n"]}],"source":["!python -m spacy download fr_core_news_sm"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:11.104601Z","iopub.status.busy":"2023-12-31T20:14:11.103179Z","iopub.status.idle":"2023-12-31T20:14:19.876799Z","shell.execute_reply":"2023-12-31T20:14:19.874811Z","shell.execute_reply.started":"2023-12-31T20:14:11.104571Z"},"trusted":true},"outputs":[],"source":["# Tokenizers\n","spacy_en = spacy.load(\"en_core_web_sm\")\n","spacy_fr = spacy.load(\"fr_core_news_sm\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create the tokenizers.\n","\n","The links below also used:\n","- [Multi30k De &lt;--&gt;En](https://www.kaggle.com/datasets/hemanthkumar21/multi30k-de-en) Dataset in kaggle\n","- [Multi30k Data Repository](https://github.com/multi30k/dataset)\n","- for [train.fr.gz](https://github.com/multi30k/dataset/blob/master/data/task1/raw/train.fr.gz) dataset\n","\n","Note: The multi30k dataset provided by torchtext.datasets contains the training/testing/validation sets for English and German, however for French it only contains a test set - even though training and validation sets are available. [Reference](https://github.com/pytorch/text/issues/762)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:19.880609Z","iopub.status.busy":"2023-12-31T20:14:19.879768Z","iopub.status.idle":"2023-12-31T20:14:19.894642Z","shell.execute_reply":"2023-12-31T20:14:19.892747Z","shell.execute_reply.started":"2023-12-31T20:14:19.880533Z"},"trusted":true},"outputs":[],"source":["def tokenize_en(text):\n","    if isinstance(text, tuple):\n","        text = text[0]  # Assuming the text to be tokenized is the first element of the tuple\n","    return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","def tokenize_fr(text):\n","    if isinstance(text, tuple):\n","        text = text[1]  # Assuming the French text is the second element of the tuple\n","    return [tok.text for tok in spacy_fr.tokenizer(text)]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:19.899468Z","iopub.status.busy":"2023-12-31T20:14:19.897448Z","iopub.status.idle":"2023-12-31T20:14:42.995703Z","shell.execute_reply":"2023-12-31T20:14:42.994116Z","shell.execute_reply.started":"2023-12-31T20:14:19.899374Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: portalocker==2.8.2 in /opt/conda/lib/python3.10/site-packages (2.8.2)\n"]}],"source":["!pip install portalocker==2.8.2"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:43.001676Z","iopub.status.busy":"2023-12-31T20:14:42.998889Z","iopub.status.idle":"2023-12-31T20:14:43.014568Z","shell.execute_reply":"2023-12-31T20:14:43.013248Z","shell.execute_reply.started":"2023-12-31T20:14:43.001496Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["File not found: /root/.cache/torch/text/datasets/Multi30k/training.tar.gz\n"]}],"source":["import os\n","file_path = '/root/.cache/torch/text/datasets/Multi30k/training.tar.gz'\n","if os.path.exists(file_path):\n","    os.remove(file_path)\n","    print(f\"Deleted corrupted file: {file_path}\")\n","else:\n","    print(f\"File not found: {file_path}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:43.017673Z","iopub.status.busy":"2023-12-31T20:14:43.017231Z","iopub.status.idle":"2023-12-31T20:14:45.341024Z","shell.execute_reply":"2023-12-31T20:14:45.339702Z","shell.execute_reply.started":"2023-12-31T20:14:43.017626Z"},"trusted":true},"outputs":[],"source":["# Function to yield tokens from the file\n","def yield_tokens_en(data_path):\n","    with open(data_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            yield tokenize_en(line)\n","            \n","# vocab_en = torchtext.vocab.build_vocab_from_iterator(map(tokenize_en, Multi30k(split='train')), specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n","vocab_en = build_vocab_from_iterator(yield_tokens_en('/kaggle/input/multi30k-de-en/training/train.en'), specials=['<unk>', '<pad>', '<bos>', '<eos>'])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:45.344699Z","iopub.status.busy":"2023-12-31T20:14:45.344426Z","iopub.status.idle":"2023-12-31T20:14:47.460092Z","shell.execute_reply":"2023-12-31T20:14:47.458787Z","shell.execute_reply.started":"2023-12-31T20:14:45.344676Z"},"trusted":true},"outputs":[],"source":["# Function to yield tokens from the file\n","def yield_tokens_fr(data_path):\n","    with open(data_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            yield tokenize_fr(line)\n","\n","vocab_fr = torchtext.vocab.build_vocab_from_iterator(yield_tokens_fr('/kaggle/input/french/train.fr'), specials=['<unk>', '<pad>', '<bos>', '<eos>'])"]},{"cell_type":"markdown","metadata":{},"source":["## Build the vocabulary."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:47.461547Z","iopub.status.busy":"2023-12-31T20:14:47.461271Z","iopub.status.idle":"2023-12-31T20:14:47.466156Z","shell.execute_reply":"2023-12-31T20:14:47.465216Z","shell.execute_reply.started":"2023-12-31T20:14:47.461523Z"},"trusted":true},"outputs":[],"source":["vocab_en.set_default_index(vocab_en['<unk>'])\n","vocab_fr.set_default_index(vocab_fr['<unk>'])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:47.468073Z","iopub.status.busy":"2023-12-31T20:14:47.467292Z","iopub.status.idle":"2023-12-31T20:14:47.479486Z","shell.execute_reply":"2023-12-31T20:14:47.478165Z","shell.execute_reply.started":"2023-12-31T20:14:47.468041Z"},"trusted":true},"outputs":[],"source":["# Custom Dataset class\n","class EuroparlDataset(Dataset):\n","    def __init__(self, file_path, vocab_en, vocab_fr, tokenizer_en, tokenizer_fr):\n","        self.pairs = []\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            for line in file:\n","                parts = line.strip().split('\\t')\n","                if len(parts) == 2:\n","                    src_sentence, trg_sentence = parts\n","                    src_indexes = [vocab_en[token] for token in tokenizer_en(src_sentence)]\n","                    trg_indexes = [vocab_fr[token] for token in tokenizer_fr(trg_sentence)]\n","                    self.pairs.append((torch.tensor(src_indexes), torch.tensor(trg_indexes)))\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, idx):\n","        return self.pairs[idx]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:47.480994Z","iopub.status.busy":"2023-12-31T20:14:47.480701Z","iopub.status.idle":"2023-12-31T20:14:47.492204Z","shell.execute_reply":"2023-12-31T20:14:47.491035Z","shell.execute_reply.started":"2023-12-31T20:14:47.480970Z"},"trusted":true},"outputs":[],"source":["# Function to create data loaders\n","def create_data_loader(file_path, vocab_en, vocab_fr, tokenizer_en, tokenizer_fr, batch_size):\n","    dataset = EuroparlDataset(file_path, vocab_en, vocab_fr, tokenizer_en, tokenizer_fr)\n","    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=generate_batch)\n","    return data_loader"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:47.493778Z","iopub.status.busy":"2023-12-31T20:14:47.493435Z","iopub.status.idle":"2023-12-31T20:14:47.507863Z","shell.execute_reply":"2023-12-31T20:14:47.506992Z","shell.execute_reply.started":"2023-12-31T20:14:47.493752Z"},"trusted":true},"outputs":[],"source":["# Function to collate data into batches\n","def generate_batch(data_batch):\n","    src_batch, trg_batch = [], []\n","    for src_item, trg_item in data_batch:\n","        src_batch.append(torch.cat([torch.tensor([vocab_en[\"<bos>\"]]), src_item, torch.tensor([vocab_en[\"<eos>\"]])], dim=0))\n","        trg_batch.append(torch.cat([torch.tensor([vocab_en[\"<bos>\"]]), trg_item, torch.tensor([vocab_en[\"<eos>\"]])], dim=0))\n","    src_batch = pad_sequence(src_batch, padding_value=vocab_en[\"<pad>\"]).to(device)\n","    trg_batch = pad_sequence(trg_batch, padding_value=vocab_en[\"<pad>\"]).to(device)\n","    return src_batch, trg_batch"]},{"cell_type":"markdown","metadata":{},"source":["## Me have made the train, validation and test set using separate file, and here we just read them."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:47.510445Z","iopub.status.busy":"2023-12-31T20:14:47.509172Z","iopub.status.idle":"2023-12-31T20:14:47.518739Z","shell.execute_reply":"2023-12-31T20:14:47.517857Z","shell.execute_reply.started":"2023-12-31T20:14:47.510407Z"},"trusted":true},"outputs":[],"source":["# Paths to the new dataset files\n","train_file = '/kaggle/input/french-english/train.txt'\n","val_file = '/kaggle/input/french-english/val.txt'\n","test_file = '/kaggle/input/french-english/test.txt'"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:14:47.520811Z","iopub.status.busy":"2023-12-31T20:14:47.520335Z","iopub.status.idle":"2023-12-31T20:23:06.554996Z","shell.execute_reply":"2023-12-31T20:23:06.553630Z","shell.execute_reply.started":"2023-12-31T20:14:47.520785Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Create data loaders was set! 64 cpu <torch.utils.data.dataloader.DataLoader object at 0x7df870b1f520> <torch.utils.data.dataloader.DataLoader object at 0x7df870b1e830> <torch.utils.data.dataloader.DataLoader object at 0x7df870b1e890>\n","Model dimensions and padding index was set! 10838 11510 1\n"]}],"source":["# Create data loaders\n","BATCH_SIZE = 64\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","train_loader = create_data_loader(train_file, vocab_en, vocab_fr, tokenize_en, tokenize_fr, BATCH_SIZE)\n","val_loader = create_data_loader(val_file, vocab_en, vocab_fr, tokenize_en, tokenize_fr, BATCH_SIZE)\n","test_loader = create_data_loader(test_file, vocab_en, vocab_fr, tokenize_en, tokenize_fr, BATCH_SIZE)\n","print(\"Create data loaders was set!\", BATCH_SIZE,device,train_loader,val_loader,test_loader)\n","\n","# Model dimensions and padding index\n","INPUT_DIM = len(vocab_en)\n","OUTPUT_DIM = len(vocab_fr)\n","TRG_PAD_IDX = vocab_en[\"<pad>\"]\n","print(\"Model dimensions and padding index was set!\", INPUT_DIM,OUTPUT_DIM,TRG_PAD_IDX)"]},{"cell_type":"markdown","metadata":{},"source":["## Building the Seq2Seq Model\n","\n","Here we have 4 parts:\n","1. Attention.\n","2. Encoder.\n","2. Decoder.\n","3. Seq2Seq model.\n","\n","### Attention\n","\n","Next up is the attention layer. This will take in the previous hidden state of the decoder, $s_{t-1}$, and all of the stacked forward and backward hidden states from the encoder, $H$. \n","\n","$$E_t = \\tanh(\\text{attn}(s_{t-1}, H))$$ \n","\n","attn is a linear layer.\n","\n","For each example in the batch as the attention should be over the length of the source sentence:\n","\n","$$\\hat{a}_t = v E_t$$\n","\n","Finally, we ensure the attention vector fits the constraints of having all elements between 0 and 1 and the vector summing to 1 by passing it through a $\\text{softmax}$ layer.\n","\n","$$a_t = \\text{softmax}(\\hat{a_t})$$\n","\n","This gives us the attention over the source sentence!\n","\n","Graphically, this looks something like below:\n","\n","![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/main/img/seq2seq9.png)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:23:06.557704Z","iopub.status.busy":"2023-12-31T20:23:06.556680Z","iopub.status.idle":"2023-12-31T20:23:06.565986Z","shell.execute_reply":"2023-12-31T20:23:06.564888Z","shell.execute_reply.started":"2023-12-31T20:23:06.557662Z"},"trusted":true},"outputs":[],"source":["# Define Attention, Encoder, Decoder, and Seq2Seq classes\n","class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n","        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n","        attention = self.v(energy).squeeze(2)\n","        return F.softmax(attention, dim=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Encoder\n","\n","First, we'll build the encoder. Similar to the previous model, we only use a single layer GRU, however we now use a *bidirectional RNN*.\n","\n","![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/main/img/seq2seq8.png)\n","\n","We now have:\n","\n","$$\\begin{align*}\n","h_t^\\rightarrow &= \\text{EncoderGRU}^\\rightarrow(e(x_t^\\rightarrow),h_{t-1}^\\rightarrow)\\\\\n","h_t^\\leftarrow &= \\text{EncoderGRU}^\\leftarrow(e(x_t^\\leftarrow),h_{t-1}^\\leftarrow)\n","\\end{align*}$$ \n","\n","The context vector:\n","\n","$$z=\\tanh(g(h_T^\\rightarrow, h_T^\\leftarrow)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$$"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:23:06.567701Z","iopub.status.busy":"2023-12-31T20:23:06.567388Z","iopub.status.idle":"2023-12-31T20:23:06.583818Z","shell.execute_reply":"2023-12-31T20:23:06.582412Z","shell.execute_reply.started":"2023-12-31T20:23:06.567678Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        embedded = self.dropout(self.embedding(src))\n","        outputs, hidden = self.rnn(embedded)\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n","        return outputs, hidden"]},{"cell_type":"markdown","metadata":{},"source":["### Decoder\n","\n","The decoder contains the attention layer, `attention`:\n","\n","$$w_t = a_t H$$\n","\n","The decoder hidden state:\n","\n","$$s_t = \\text{DecoderGRU}(d(y_t), w_t, s_{t-1})$$\n","\n","To make a prediction of the next word in the target sentence, $\\hat{y}_{t+1}$:\n","\n","$$\\hat{y}_{t+1} = f(d(y_t), w_t, s_t)$$\n","\n","The image below shows decoding the first word in an example translation.\n","\n","![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/main/img/seq2seq10.png)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:23:06.586945Z","iopub.status.busy":"2023-12-31T20:23:06.586071Z","iopub.status.idle":"2023-12-31T20:23:06.597740Z","shell.execute_reply":"2023-12-31T20:23:06.596651Z","shell.execute_reply.started":"2023-12-31T20:23:06.586841Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        input = input.unsqueeze(0)\n","        embedded = self.dropout(self.embedding(input))\n","        a = self.attention(hidden, encoder_outputs)\n","        a = a.unsqueeze(1)\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        weighted = torch.bmm(a, encoder_outputs)\n","        weighted = weighted.permute(1, 0, 2)\n","        rnn_input = torch.cat((embedded, weighted), dim=2)\n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n","        return prediction, hidden.squeeze(0)"]},{"cell_type":"markdown","metadata":{},"source":["### Seq2Seq"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:23:06.599631Z","iopub.status.busy":"2023-12-31T20:23:06.599151Z","iopub.status.idle":"2023-12-31T20:23:06.617360Z","shell.execute_reply":"2023-12-31T20:23:06.616028Z","shell.execute_reply.started":"2023-12-31T20:23:06.599606Z"},"trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        encoder_outputs, hidden = self.encoder(src)\n","        input = trg[0, :]\n","        for t in range(1, trg_len):\n","            output, hidden = self.decoder(input, hidden, encoder_outputs)\n","            outputs[t] = output\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            top1 = output.argmax(1)\n","            input = trg[t] if teacher_force else top1\n","        return outputs"]},{"cell_type":"markdown","metadata":{},"source":["## Training the Model\n","\n","Also, we used Adam optimizer."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:23:06.619536Z","iopub.status.busy":"2023-12-31T20:23:06.619141Z","iopub.status.idle":"2023-12-31T20:23:07.555150Z","shell.execute_reply":"2023-12-31T20:23:07.553809Z","shell.execute_reply.started":"2023-12-31T20:23:06.619501Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 32,791,798 trainable parameters\n"]}],"source":["# Instantiate the model\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","ENC_HID_DIM = 512\n","DEC_HID_DIM = 512\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, device).to(device)\n","\n","# Model training setup\n","# optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","optimizer = optim.Adam(model.parameters())\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n","\n","# Initialize weights\n","def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","\n","model.apply(init_weights)\n","\n","# Define a function to count the number of trainable parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"markdown","metadata":{},"source":["## Create the training loop... and the evaluation loop, \n","## and finally, define a timing function."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:23:07.558234Z","iopub.status.busy":"2023-12-31T20:23:07.557916Z","iopub.status.idle":"2023-12-31T20:23:07.570195Z","shell.execute_reply":"2023-12-31T20:23:07.568610Z","shell.execute_reply.started":"2023-12-31T20:23:07.558211Z"},"trusted":true},"outputs":[],"source":["# Training and evaluation functions\n","def train(model, iterator, optimizer, criterion, clip):\n","    model.train()\n","    epoch_loss = 0\n","    progress_bar = tqdm(iterator, total=len(iterator), desc='Training', leave=False)\n","\n","    for i, batch in enumerate(iterator):\n","        src, trg = batch\n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        output_dim = output.shape[-1]\n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        loss = criterion(output, trg)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","    return epoch_loss / len(iterator)\n","\n","# Evaluation function\n","def evaluate(model, iterator, criterion):\n","    model.eval()\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src, trg = batch\n","            output = model(src, trg, 0)  # Turn off teacher forcing\n","            output_dim = output.shape[-1]\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","            loss = criterion(output, trg)\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","# Time calculation function\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"markdown","metadata":{},"source":["## Then, train the model, saving the parameters that give us the best validation loss."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-31T20:23:07.572475Z","iopub.status.busy":"2023-12-31T20:23:07.571959Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/18776 [3:12:54<?, ?it/s, loss=4.23]"]}],"source":["# Training loop\n","N_EPOCHS = 3  # Number of epochs - adjust as needed\n","CLIP = 1       # Gradient clip threshold\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    start_time = time.time()\n","    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, val_loader, criterion)\n","    end_time = time.time()\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss                            \n","        torch.save(model.state_dict(), 'tut-model.pt')\n","\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f}')"]},{"cell_type":"markdown","metadata":{},"source":["## Finally, test the model on the test set using these \"best\" parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load the best model                            \n","model.load_state_dict(torch.load('tut-model.pt'))\n","\n","# Test the model\n","test_loss = evaluate(model, test_loader, criterion)\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"]},{"cell_type":"markdown","metadata":{},"source":["## Final Report:\n","\n","We've improved on the previous model. \n","First, we tried on the local system and then, kaggle notebook.\n","The best **loss that we achieved was 1.26** on local system, that was better than other implementations"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3944299,"sourceId":6863003,"sourceType":"datasetVersion"},{"datasetId":4244205,"sourceId":7313890,"sourceType":"datasetVersion"},{"datasetId":4244221,"sourceId":7313914,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
