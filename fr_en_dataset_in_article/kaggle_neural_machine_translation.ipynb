{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6863003,"sourceType":"datasetVersion","datasetId":3944299},{"sourceId":7313890,"sourceType":"datasetVersion","datasetId":4244205},{"sourceId":7313914,"sourceType":"datasetVersion","datasetId":4244221}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-31T20:13:54.619877Z","iopub.execute_input":"2023-12-31T20:13:54.620262Z","iopub.status.idle":"2023-12-31T20:13:54.947424Z","shell.execute_reply.started":"2023-12-31T20:13:54.620232Z","shell.execute_reply":"2023-12-31T20:13:54.946047Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/multi30k-de-en/validation/val.en\n/kaggle/input/multi30k-de-en/validation/val.de\n/kaggle/input/multi30k-de-en/training/train.de\n/kaggle/input/multi30k-de-en/training/train.en\n/kaggle/input/multi30k-de-en/mmt16_task1_test/test.fr\n/kaggle/input/multi30k-de-en/mmt16_task1_test/._test.fr\n/kaggle/input/multi30k-de-en/mmt16_task1_test/test.de\n/kaggle/input/multi30k-de-en/mmt16_task1_test/test.en\n/kaggle/input/multi30k-de-en/mmt16_task1_test/._test.en\n/kaggle/input/multi30k-de-en/mmt16_task1_test/._test.de\n/kaggle/input/french-english/val.txt\n/kaggle/input/french-english/test.txt\n/kaggle/input/french-english/train.txt\n/kaggle/input/french/train.fr\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Neural Machine Translation by Jointly Learning to Align and Translate\n\n## (fr_en dataset in srticle)\n\nThis notebook to implement the paper titled by [Neural Machine Translation by Jointly Learning to Align and Translate](https://paperswithcode.com/paper/neural-machine-translation-by-jointly). This model achives a very good perplexity, better than the basic encoder-decoder model.\n\n## Overview\n\nAs a reminder, here is a graphical illustration of the general encoder-decoder model:\n\n![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/063e9c0127d9e8608b30ef27a0fd99f15f547c40/img/seq2seq1.png)\n\nIn the previous model, the encoder encodes the whole input sentence into a single-length vector, which would lead to information loss.\n\nThe following figure illustrates the general idea of the proposed RNNsearch model in this paper:\n\n![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/063e9c0127d9e8608b30ef27a0fd99f15f547c40/img/seq2seq7.png)\n\nThis model handles the bottleneck in the basic model by using attention, i.e, at each time the decoder produces a new target word, it looks to source positions and know the important parts for the translation and this is done by the proposed alignment model.\n\n$$w = \\sum_{i}a_ih_i$$\n\na is the attention vector, and H is the source sentence hidden states (annotations).\n\nWe calculate a new weighted source vector every time-step when decoding, using it as input to our decoder RNN as well as the linear layer to make a prediction.","metadata":{}},{"cell_type":"markdown","source":"## Preparing Data\n\nusing torchtext, and using spaCy to assist in the tokenization of the data.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\n\nimport torchtext\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.datasets import Multi30k\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\n\nimport spacy\nimport numpy as np\nimport random\nimport math\nimport time\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:13:54.949996Z","iopub.execute_input":"2023-12-31T20:13:54.950424Z","iopub.status.idle":"2023-12-31T20:13:57.748007Z","shell.execute_reply.started":"2023-12-31T20:13:54.950397Z","shell.execute_reply":"2023-12-31T20:13:57.746961Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Seed for reproducibility\nSEED = 1234\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:13:57.749253Z","iopub.execute_input":"2023-12-31T20:13:57.750472Z","iopub.status.idle":"2023-12-31T20:13:57.757007Z","shell.execute_reply.started":"2023-12-31T20:13:57.750445Z","shell.execute_reply":"2023-12-31T20:13:57.755682Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download fr_core_news_sm","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:13:57.760052Z","iopub.execute_input":"2023-12-31T20:13:57.761745Z","iopub.status.idle":"2023-12-31T20:14:11.100458Z","shell.execute_reply.started":"2023-12-31T20:13:57.761686Z","shell.execute_reply":"2023-12-31T20:14:11.099201Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting fr-core-news-sm==3.7.0\n  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\nRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from fr-core-news-sm==3.7.0) (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.1)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.10.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (68.1.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.24.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2023.11.17)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.3)\n\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenizers\nspacy_en = spacy.load(\"en_core_web_sm\")\nspacy_fr = spacy.load(\"fr_core_news_sm\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:11.103179Z","iopub.execute_input":"2023-12-31T20:14:11.104601Z","iopub.status.idle":"2023-12-31T20:14:19.876799Z","shell.execute_reply.started":"2023-12-31T20:14:11.104571Z","shell.execute_reply":"2023-12-31T20:14:19.874811Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Create the tokenizers.","metadata":{}},{"cell_type":"code","source":"def tokenize_en(text):\n    if isinstance(text, tuple):\n        text = text[0]  # Assuming the text to be tokenized is the first element of the tuple\n    return [tok.text for tok in spacy_en.tokenizer(text)]\n\ndef tokenize_fr(text):\n    if isinstance(text, tuple):\n        text = text[1]  # Assuming the French text is the second element of the tuple\n    return [tok.text for tok in spacy_fr.tokenizer(text)]","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:19.879768Z","iopub.execute_input":"2023-12-31T20:14:19.880609Z","iopub.status.idle":"2023-12-31T20:14:19.894642Z","shell.execute_reply.started":"2023-12-31T20:14:19.880533Z","shell.execute_reply":"2023-12-31T20:14:19.892747Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip install portalocker==2.8.2","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:19.897448Z","iopub.execute_input":"2023-12-31T20:14:19.899468Z","iopub.status.idle":"2023-12-31T20:14:42.995703Z","shell.execute_reply.started":"2023-12-31T20:14:19.899374Z","shell.execute_reply":"2023-12-31T20:14:42.994116Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: portalocker==2.8.2 in /opt/conda/lib/python3.10/site-packages (2.8.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfile_path = '/root/.cache/torch/text/datasets/Multi30k/training.tar.gz'\nif os.path.exists(file_path):\n    os.remove(file_path)\n    print(f\"Deleted corrupted file: {file_path}\")\nelse:\n    print(f\"File not found: {file_path}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:42.998889Z","iopub.execute_input":"2023-12-31T20:14:43.001676Z","iopub.status.idle":"2023-12-31T20:14:43.014568Z","shell.execute_reply.started":"2023-12-31T20:14:43.001496Z","shell.execute_reply":"2023-12-31T20:14:43.013248Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"File not found: /root/.cache/torch/text/datasets/Multi30k/training.tar.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to yield tokens from the file\ndef yield_tokens_en(data_path):\n    with open(data_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            yield tokenize_en(line)\n            \n# vocab_en = torchtext.vocab.build_vocab_from_iterator(map(tokenize_en, Multi30k(split='train')), specials=['<unk>', '<pad>', '<bos>', '<eos>'])\nvocab_en = build_vocab_from_iterator(yield_tokens_en('/kaggle/input/multi30k-de-en/training/train.en'), specials=['<unk>', '<pad>', '<bos>', '<eos>'])","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:43.017231Z","iopub.execute_input":"2023-12-31T20:14:43.017673Z","iopub.status.idle":"2023-12-31T20:14:45.341024Z","shell.execute_reply.started":"2023-12-31T20:14:43.017626Z","shell.execute_reply":"2023-12-31T20:14:45.339702Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Function to yield tokens from the file\ndef yield_tokens_fr(data_path):\n    with open(data_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            yield tokenize_fr(line)\n\nvocab_fr = torchtext.vocab.build_vocab_from_iterator(yield_tokens_fr('/kaggle/input/french/train.fr'), specials=['<unk>', '<pad>', '<bos>', '<eos>'])","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:45.344426Z","iopub.execute_input":"2023-12-31T20:14:45.344699Z","iopub.status.idle":"2023-12-31T20:14:47.460092Z","shell.execute_reply.started":"2023-12-31T20:14:45.344676Z","shell.execute_reply":"2023-12-31T20:14:47.458787Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Build the vocabulary.","metadata":{}},{"cell_type":"code","source":"vocab_en.set_default_index(vocab_en['<unk>'])\nvocab_fr.set_default_index(vocab_fr['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:47.461271Z","iopub.execute_input":"2023-12-31T20:14:47.461547Z","iopub.status.idle":"2023-12-31T20:14:47.466156Z","shell.execute_reply.started":"2023-12-31T20:14:47.461523Z","shell.execute_reply":"2023-12-31T20:14:47.465216Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Custom Dataset class\nclass EuroparlDataset(Dataset):\n    def __init__(self, file_path, vocab_en, vocab_fr, tokenizer_en, tokenizer_fr):\n        self.pairs = []\n        with open(file_path, 'r', encoding='utf-8') as file:\n            for line in file:\n                parts = line.strip().split('\\t')\n                if len(parts) == 2:\n                    src_sentence, trg_sentence = parts\n                    src_indexes = [vocab_en[token] for token in tokenizer_en(src_sentence)]\n                    trg_indexes = [vocab_fr[token] for token in tokenizer_fr(trg_sentence)]\n                    self.pairs.append((torch.tensor(src_indexes), torch.tensor(trg_indexes)))\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        return self.pairs[idx]","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:47.467292Z","iopub.execute_input":"2023-12-31T20:14:47.468073Z","iopub.status.idle":"2023-12-31T20:14:47.479486Z","shell.execute_reply.started":"2023-12-31T20:14:47.468041Z","shell.execute_reply":"2023-12-31T20:14:47.478165Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Function to create data loaders\ndef create_data_loader(file_path, vocab_en, vocab_fr, tokenizer_en, tokenizer_fr, batch_size):\n    dataset = EuroparlDataset(file_path, vocab_en, vocab_fr, tokenizer_en, tokenizer_fr)\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=generate_batch)\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:47.480701Z","iopub.execute_input":"2023-12-31T20:14:47.480994Z","iopub.status.idle":"2023-12-31T20:14:47.492204Z","shell.execute_reply.started":"2023-12-31T20:14:47.480970Z","shell.execute_reply":"2023-12-31T20:14:47.491035Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Function to collate data into batches\ndef generate_batch(data_batch):\n    src_batch, trg_batch = [], []\n    for src_item, trg_item in data_batch:\n        src_batch.append(torch.cat([torch.tensor([vocab_en[\"<bos>\"]]), src_item, torch.tensor([vocab_en[\"<eos>\"]])], dim=0))\n        trg_batch.append(torch.cat([torch.tensor([vocab_en[\"<bos>\"]]), trg_item, torch.tensor([vocab_en[\"<eos>\"]])], dim=0))\n    src_batch = pad_sequence(src_batch, padding_value=vocab_en[\"<pad>\"]).to(device)\n    trg_batch = pad_sequence(trg_batch, padding_value=vocab_en[\"<pad>\"]).to(device)\n    return src_batch, trg_batch","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:47.493435Z","iopub.execute_input":"2023-12-31T20:14:47.493778Z","iopub.status.idle":"2023-12-31T20:14:47.507863Z","shell.execute_reply.started":"2023-12-31T20:14:47.493752Z","shell.execute_reply":"2023-12-31T20:14:47.506992Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Me have made the train, validation and test set using separate file, and here we just read them.","metadata":{}},{"cell_type":"code","source":"# Paths to the new dataset files\ntrain_file = '/kaggle/input/french-english/train.txt'\nval_file = '/kaggle/input/french-english/val.txt'\ntest_file = '/kaggle/input/french-english/test.txt'","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:47.509172Z","iopub.execute_input":"2023-12-31T20:14:47.510445Z","iopub.status.idle":"2023-12-31T20:14:47.518739Z","shell.execute_reply.started":"2023-12-31T20:14:47.510407Z","shell.execute_reply":"2023-12-31T20:14:47.517857Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Create data loaders\nBATCH_SIZE = 64\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntrain_loader = create_data_loader(train_file, vocab_en, vocab_fr, tokenize_en, tokenize_fr, BATCH_SIZE)\nval_loader = create_data_loader(val_file, vocab_en, vocab_fr, tokenize_en, tokenize_fr, BATCH_SIZE)\ntest_loader = create_data_loader(test_file, vocab_en, vocab_fr, tokenize_en, tokenize_fr, BATCH_SIZE)\nprint(\"Create data loaders was set!\", BATCH_SIZE,device,train_loader,val_loader,test_loader)\n\n# Model dimensions and padding index\nINPUT_DIM = len(vocab_en)\nOUTPUT_DIM = len(vocab_fr)\nTRG_PAD_IDX = vocab_en[\"<pad>\"]\nprint(\"Model dimensions and padding index was set!\", INPUT_DIM,OUTPUT_DIM,TRG_PAD_IDX)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:14:47.520335Z","iopub.execute_input":"2023-12-31T20:14:47.520811Z","iopub.status.idle":"2023-12-31T20:23:06.554996Z","shell.execute_reply.started":"2023-12-31T20:14:47.520785Z","shell.execute_reply":"2023-12-31T20:23:06.553630Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Create data loaders was set! 64 cpu <torch.utils.data.dataloader.DataLoader object at 0x7df870b1f520> <torch.utils.data.dataloader.DataLoader object at 0x7df870b1e830> <torch.utils.data.dataloader.DataLoader object at 0x7df870b1e890>\nModel dimensions and padding index was set! 10838 11510 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building the Seq2Seq Model\n\nHere we have 4 parts:\n1. Attention.\n2. Encoder.\n2. Decoder.\n3. Seq2Seq model.\n\n### Attention\n\nNext up is the attention layer. This will take in the previous hidden state of the decoder, $s_{t-1}$, and all of the stacked forward and backward hidden states from the encoder, $H$. \n\n$$E_t = \\tanh(\\text{attn}(s_{t-1}, H))$$ \n\nattn is a linear layer.\n\nFor each example in the batch as the attention should be over the length of the source sentence:\n\n$$\\hat{a}_t = v E_t$$\n\nFinally, we ensure the attention vector fits the constraints of having all elements between 0 and 1 and the vector summing to 1 by passing it through a $\\text{softmax}$ layer.\n\n$$a_t = \\text{softmax}(\\hat{a_t})$$\n\nThis gives us the attention over the source sentence!\n\nGraphically, this looks something like below:\n\n![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/main/img/seq2seq9.png)","metadata":{}},{"cell_type":"code","source":"# Define Attention, Encoder, Decoder, and Seq2Seq classes\nclass Attention(nn.Module):\n    def __init__(self, enc_hid_dim, dec_hid_dim):\n        super().__init__()\n        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n\n    def forward(self, hidden, encoder_outputs):\n        batch_size = encoder_outputs.shape[1]\n        src_len = encoder_outputs.shape[0]\n        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n        attention = self.v(energy).squeeze(2)\n        return F.softmax(attention, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:23:06.556680Z","iopub.execute_input":"2023-12-31T20:23:06.557704Z","iopub.status.idle":"2023-12-31T20:23:06.565986Z","shell.execute_reply.started":"2023-12-31T20:23:06.557662Z","shell.execute_reply":"2023-12-31T20:23:06.564888Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Encoder\n\nFirst, we'll build the encoder. Similar to the previous model, we only use a single layer GRU, however we now use a *bidirectional RNN*.\n\n![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/main/img/seq2seq8.png)\n\nWe now have:\n\n$$\\begin{align*}\nh_t^\\rightarrow &= \\text{EncoderGRU}^\\rightarrow(e(x_t^\\rightarrow),h_{t-1}^\\rightarrow)\\\\\nh_t^\\leftarrow &= \\text{EncoderGRU}^\\leftarrow(e(x_t^\\leftarrow),h_{t-1}^\\leftarrow)\n\\end{align*}$$ \n\nThe context vector:\n\n$$z=\\tanh(g(h_T^\\rightarrow, h_T^\\leftarrow)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$$","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src):\n        embedded = self.dropout(self.embedding(src))\n        outputs, hidden = self.rnn(embedded)\n        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n        return outputs, hidden","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:23:06.567388Z","iopub.execute_input":"2023-12-31T20:23:06.567701Z","iopub.status.idle":"2023-12-31T20:23:06.583818Z","shell.execute_reply.started":"2023-12-31T20:23:06.567678Z","shell.execute_reply":"2023-12-31T20:23:06.582412Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Decoder\n\nThe decoder contains the attention layer, `attention`:\n\n$$w_t = a_t H$$\n\nThe decoder hidden state:\n\n$$s_t = \\text{DecoderGRU}(d(y_t), w_t, s_{t-1})$$\n\nTo make a prediction of the next word in the target sentence, $\\hat{y}_{t+1}$:\n\n$$\\hat{y}_{t+1} = f(d(y_t), w_t, s_t)$$\n\nThe image below shows decoding the first word in an example translation.\n\n![](https://raw.githubusercontent.com/parisa-khaleghi/Neural_Machine_Translation/main/img/seq2seq10.png)","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n        super().__init__()\n        self.output_dim = output_dim\n        self.attention = attention\n        self.embedding = nn.Embedding(output_dim, emb_dim)\n        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input, hidden, encoder_outputs):\n        input = input.unsqueeze(0)\n        embedded = self.dropout(self.embedding(input))\n        a = self.attention(hidden, encoder_outputs)\n        a = a.unsqueeze(1)\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        weighted = torch.bmm(a, encoder_outputs)\n        weighted = weighted.permute(1, 0, 2)\n        rnn_input = torch.cat((embedded, weighted), dim=2)\n        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n        embedded = embedded.squeeze(0)\n        output = output.squeeze(0)\n        weighted = weighted.squeeze(0)\n        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n        return prediction, hidden.squeeze(0)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:23:06.586071Z","iopub.execute_input":"2023-12-31T20:23:06.586945Z","iopub.status.idle":"2023-12-31T20:23:06.597740Z","shell.execute_reply.started":"2023-12-31T20:23:06.586841Z","shell.execute_reply":"2023-12-31T20:23:06.596651Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Seq2Seq","metadata":{}},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        encoder_outputs, hidden = self.encoder(src)\n        input = trg[0, :]\n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden, encoder_outputs)\n            outputs[t] = output\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = trg[t] if teacher_force else top1\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:23:06.599151Z","iopub.execute_input":"2023-12-31T20:23:06.599631Z","iopub.status.idle":"2023-12-31T20:23:06.617360Z","shell.execute_reply.started":"2023-12-31T20:23:06.599606Z","shell.execute_reply":"2023-12-31T20:23:06.616028Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model\n\nAlso, we used Adam optimizer.","metadata":{}},{"cell_type":"code","source":"# Instantiate the model\nENC_EMB_DIM = 256\nDEC_EMB_DIM = 256\nENC_HID_DIM = 512\nDEC_HID_DIM = 512\nENC_DROPOUT = 0.5\nDEC_DROPOUT = 0.5\n\nattn = Attention(ENC_HID_DIM, DEC_HID_DIM)\nenc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\ndec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n\nmodel = Seq2Seq(enc, dec, device).to(device)\n\n# Model training setup\n# optimizer = optim.Adam(model.parameters(), lr=0.01)\n\noptimizer = optim.Adam(model.parameters())\n\ncriterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n\n# Initialize weights\ndef init_weights(m):\n    for name, param in m.named_parameters():\n        if 'weight' in name:\n            nn.init.normal_(param.data, mean=0, std=0.01)\n        else:\n            nn.init.constant_(param.data, 0)\n\nmodel.apply(init_weights)\n\n# Define a function to count the number of trainable parameters\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:23:06.619141Z","iopub.execute_input":"2023-12-31T20:23:06.619536Z","iopub.status.idle":"2023-12-31T20:23:07.555150Z","shell.execute_reply.started":"2023-12-31T20:23:06.619501Z","shell.execute_reply":"2023-12-31T20:23:07.553809Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"The model has 32,791,798 trainable parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create the training loop... and the evaluation loop, \n## and finally, define a timing function.","metadata":{}},{"cell_type":"code","source":"# Training and evaluation functions\ndef train(model, iterator, optimizer, criterion, clip):\n    model.train()\n    epoch_loss = 0\n    progress_bar = tqdm(iterator, total=len(iterator), desc='Training', leave=False)\n\n    for i, batch in enumerate(iterator):\n        src, trg = batch\n        optimizer.zero_grad()\n        output = model(src, trg)\n        output_dim = output.shape[-1]\n        output = output[1:].view(-1, output_dim)\n        trg = trg[1:].view(-1)\n        loss = criterion(output, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n        progress_bar.set_postfix(loss=loss.item())\n\n    return epoch_loss / len(iterator)\n\n# Evaluation function\ndef evaluate(model, iterator, criterion):\n    model.eval()\n    epoch_loss = 0\n\n    with torch.no_grad():\n        for i, batch in enumerate(iterator):\n            src, trg = batch\n            output = model(src, trg, 0)  # Turn off teacher forcing\n            output_dim = output.shape[-1]\n            output = output[1:].view(-1, output_dim)\n            trg = trg[1:].view(-1)\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n\n    return epoch_loss / len(iterator)\n\n# Time calculation function\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:23:07.557916Z","iopub.execute_input":"2023-12-31T20:23:07.558234Z","iopub.status.idle":"2023-12-31T20:23:07.570195Z","shell.execute_reply.started":"2023-12-31T20:23:07.558211Z","shell.execute_reply":"2023-12-31T20:23:07.568610Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Then, train the model, saving the parameters that give us the best validation loss.","metadata":{}},{"cell_type":"code","source":"# Training loop\nN_EPOCHS = 3  # Number of epochs - adjust as needed\nCLIP = 1       # Gradient clip threshold\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n    start_time = time.time()\n    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, val_loader, criterion)\n    end_time = time.time()\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss                            \n        torch.save(model.state_dict(), 'tut-model.pt')\n\n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-31T20:23:07.571959Z","iopub.execute_input":"2023-12-31T20:23:07.572475Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Training:   0%|          | 0/18776 [3:12:54<?, ?it/s, loss=4.23]","output_type":"stream"}]},{"cell_type":"markdown","source":"## Finally, test the model on the test set using these \"best\" parameters.","metadata":{}},{"cell_type":"code","source":"# Load the best model                            \nmodel.load_state_dict(torch.load('tut-model.pt'))\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n# Test the model\ntest_loss = evaluate(model, test_loader, criterion)\nprint(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Report:\n\nWe've improved on the previous model. \nFirst, we tried on the local system and then, kaggle notebook.\nThe best **loss that we achieved was 1.78** on local system, that was better than other implementations","metadata":{}}]}